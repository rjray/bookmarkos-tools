#!/usr/bin/env python3
"""A general script to produce a series of different reports on bookmarks data
as transformed to JSON by the `bookmarks2json` tool."""

import argparse
from bisect import bisect_left
from datetime import timedelta, datetime
from operator import attrgetter
import re
import sys
from typing import TextIO

from bookmarkos.data.bookmarks import Folder, Bookmark
from bookmarkos.data.metrics import Metrics, SizeMetrics
from bookmarkos.json_io import read_bookmarks_json


def parse_command_line() -> argparse.Namespace:
    """Declaration of command-line parameters and parsing of them."""

    parser = argparse.ArgumentParser()

    parser.add_argument(
        'command', action='store', nargs=1,
        choices=['weekly'], help='Report to run'
    )
    parser.add_argument(
        'files', action='store', nargs='+',
        help='One or more JSON files to process'
    )

    return parser.parse_args()


def datetime_from_filename(file: str) -> datetime:
    """Scan the given file-name for a sequence of 8 digits, which will be
    interpreted as yyyy/mm/dd."""

    match = re.search(r'(\d\d\d\d)(\d\d)(\d\d)', file)
    if match is None:
        raise ValueError('File name does not contain date')

    # Create the `datetime` from the year/month/day. Seems like I should be
    # able to use `map` over `match.group(1, 2, 3)` here...?
    return datetime(
        int(match.group(1)), int(match.group(2)), int(match.group(3))
    )


def average_size(metrics: SizeMetrics) -> float:
    """Calculate the average size for either `folders` or `tags`."""

    sizes = metrics.sizes
    count = len(sizes)
    total = sum(sizes[x] for x in sizes.keys())

    return total / count


def gather_metrics(week: Folder) -> Metrics:
    """Determine the metrics of the given week's data."""

    metrics = Metrics()

    # Start the recursive gathering from `week` (the root folder) with a null
    # folder-name element and the fresh `Metrics` object.
    _gather_metrics(week, [''], metrics)

    # Calculate averages
    metrics.tags.avg_size = average_size(metrics.tags)
    metrics.folders.avg_size = average_size(metrics.folders)

    # Sort `all_bookmarks` by `created` field
    metrics.all_bookmarks.sort(key=attrgetter('created'))

    return metrics


def _gather_metrics(node: Folder, path: list[str], metrics: Metrics) -> None:
    """Recursively gather metrics at folder `node`."""

    # Used to make unique identifier for the folder. THe "::" sequence is used
    # because folder names can (and do) contain "/".
    folder = '::'.join(path)

    # Get the size, then separate content into bookmarks and sub-folders.
    folder_size = len(node.content)
    bookmarks = [x for x in node.content if isinstance(x, Bookmark)]
    subfolders = [x for x in node.content if isinstance(x, Folder)]

    # Folder-oriented metrics
    metrics.folders.count += 1
    metrics.folders.items.add(folder)
    metrics.folders.sizes[folder] = folder_size
    metrics.folders.max_size = max(metrics.folders.max_size, folder_size)
    metrics.folders.min_size = min(metrics.folders.min_size, folder_size)

    # Process bookmarks, for bookmark-oriented and tag-oriented metrics
    metrics.bookmarks.count += len(bookmarks)
    for bookmark in bookmarks:
        metrics.bookmarks.items.add(bookmark.created)
        metrics.all_bookmarks.append(bookmark)

        num_tags = len(bookmark.tags)
        metrics.tags.count += num_tags
        metrics.tags.max_size = max(metrics.tags.max_size, num_tags)
        metrics.tags.min_size = min(metrics.tags.min_size, num_tags)

        for tag in bookmark.tags:
            metrics.tags.items.add(tag)
            if tag not in metrics.tags.sizes:
                metrics.tags.sizes[tag] = 1
            else:
                metrics.tags.sizes[tag] += 1

    for subfolder in subfolders:
        # Seems the only way to prevent corruption of the `path` list is to
        # explicitly copy it and append the new name.
        newpath = path.copy()
        newpath.append(subfolder.name)
        _gather_metrics(subfolder, newpath, metrics)


def get_metrics(week_file: str) -> Metrics:
    """Read the JSON data from `week_file` for a given week, then call
    `gather_metrics` to determine the metrics for the week."""

    return gather_metrics(read_bookmarks_json(week_file))


def finish_metrics(this_week: Metrics, last_week: Metrics):
    """Calculate the additional values (differences, etc.) between two sets of
    metrics. These values only update the current-week's metrics."""

    # Additional values for bookmarks
    this_week.bookmarks.delta = \
        this_week.bookmarks.count - last_week.bookmarks.count
    this_week.bookmarks.delta_pct = \
        this_week.bookmarks.delta / last_week.bookmarks.count
    this_week.bookmarks.added = \
        this_week.bookmarks.items - last_week.bookmarks.items
    this_week.bookmarks.added_count = len(this_week.bookmarks.added)
    this_week.bookmarks.deleted = \
        last_week.bookmarks.items - this_week.bookmarks.items
    this_week.bookmarks.deleted_count = len(this_week.bookmarks.deleted)

    # Additional values for folders
    this_week.folders.delta = this_week.folders.count - last_week.folders.count
    this_week.folders.delta_pct = \
        this_week.folders.delta / last_week.folders.count
    this_week.folders.added = this_week.folders.items - last_week.folders.items
    this_week.folders.added_count = len(this_week.folders.added)
    this_week.folders.deleted = \
        last_week.folders.items - this_week.folders.items
    this_week.folders.deleted_count = len(this_week.folders.deleted)

    # Additional values for tags
    this_tags = this_week.tags.items
    last_tags = last_week.tags.items
    this_week.tags.unique_tags_count = len(this_tags)
    last_week.tags.unique_tags_count = len(last_tags)
    this_week.tags.delta = this_week.tags.unique_tags_count - \
        last_week.tags.unique_tags_count
    this_week.tags.delta_pct = \
        this_week.tags.delta / last_week.tags.unique_tags_count
    this_week.tags.added = this_tags - last_tags
    this_week.tags.added_count = len(this_week.tags.added)
    this_week.tags.deleted = last_tags - this_tags
    this_week.tags.deleted_count = len(this_week.tags.deleted)


def format_bookmark(bookmark: Bookmark) -> str:
    """Format the bookmark as a hyperlink."""

    created = datetime.fromtimestamp(bookmark.created).astimezone()
    timestamp = created.ctime()

    return f"{bookmark.name} ({timestamp})"


def output(lines: list[tuple[str, int | str]], fp: TextIO) -> None:
    """Output the pairs provided."""

    for label, value in lines:
        print(f"{label:25} {value}", file=fp)


def output_folders_weekly(these: Metrics, fp: TextIO) -> None:
    """Weekly output for folder metrics."""

    metrics = these.folders

    content: list[tuple[str, int | str]] = [('Total folders:', metrics.count)]
    if metrics.added_count:
        content.append(('Folders added:', metrics.added_count))
    if metrics.deleted_count:
        content.append(('Folders deleted:', metrics.deleted_count))
    if metrics.delta:
        content.append(
            (
                'Folders delta:',
                f'{metrics.delta} ({(metrics.delta_pct * 100):.2f}%)'
            )
        )

    if metrics.added_count:
        added = sorted(list(metrics.added))

        content.append(('    Added folders:', added[0]))
        for item in added[1:]:
            content.append(('', item))

    if metrics.deleted_count:
        deleted = sorted(list(metrics.deleted))

        content.append(('    Deleted folders:', deleted[0]))
        for item in deleted[1:]:
            content.append(('', item))

    content.append(
        (
            'Largest folder size:',
            max(metrics.sizes[x] for x in metrics.sizes.keys())
        )
    )
    content.append(
        (
            'Smallest folder size:',
            min(metrics.sizes[x] for x in metrics.sizes.keys())
        )
    )
    content.append(('Average folder size:', f'{metrics.avg_size:.2f}'))
    output(content, fp)


def output_bookmarks_weekly(these: Metrics, those: Metrics, fp: TextIO) -> None:
    """Weekly output for bookmark metrics."""

    metrics = these.bookmarks
    bookmarks = these.all_bookmarks

    content: list[tuple[str, int | str]] = [
        ('Total bookmarks:', metrics.count)
    ]
    if metrics.added_count:
        content.append(('Bookmarks added:', metrics.added_count))
    if metrics.deleted_count:
        content.append(('Bookmarks deleted:', metrics.deleted_count))
    if metrics.delta:
        content.append(
            (
                'Bookmarks delta:',
                f"{metrics.delta} ({(metrics.delta_pct * 100):.2f}%)"
            )
        )

    if metrics.added_count:
        added = []
        for item in sorted(list(metrics.added)):
            pos = bisect_left(bookmarks, item, key=attrgetter('created'))
            added.append(format_bookmark(bookmarks[pos]))

        content.append(('    Added bookmarks:', added[0]))
        for item in added[1:]:
            content.append(('', item))

    if metrics.deleted_count:
        bookmarks2 = those.all_bookmarks
        deleted = []
        for item in sorted(list(metrics.deleted)):
            pos = bisect_left(bookmarks2, item, key=attrgetter('created'))
            deleted.append(format_bookmark(bookmarks2[pos]))

        content.append(('    Deleted bookmarks:', deleted[0]))
        for item in deleted[1:]:
            content.append(('', item))

    output(content, fp)


def output_tags_weekly(these: Metrics, fp: TextIO) -> None:
    """Weekly output for tag metrics."""

    metrics = these.tags

    content: list[tuple[str, int | str]] = [
        ('Total tags:', metrics.count),
        ('Unique tags:', metrics.unique_tags_count)
    ]
    if metrics.added_count:
        content.append(('New tags added:', metrics.added_count))
    if metrics.deleted_count:
        content.append(('Old tags deleted:', metrics.deleted_count))
    if metrics.delta:
        content.append(
            (
                'Tags delta:',
                f'{metrics.delta} ({(metrics.delta_pct * 100):.2f}%)'
            )
        )

    if metrics.added_count:
        added = sorted(list(metrics.added))

        content.append(('    Added tags:', added[0]))
        for item in added[1:]:
            content.append(('', item))

    if metrics.deleted_count:
        deleted = sorted(list(metrics.deleted))

        content.append(('    Deleted tags:', deleted[0]))
        for item in deleted[1:]:
            content.append(('', item))

    content.append(
        (
            'Largest tag size:',
            max(metrics.sizes[x] for x in metrics.sizes.keys())
        )
    )
    content.append(
        (
            'Smallest tag size:',
            min(metrics.sizes[x] for x in metrics.sizes.keys())
        )
    )
    content.append(('Average tag reach:', f'{metrics.avg_size:.2f}'))
    content.append(('Highest number of tags:', metrics.max_size))
    content.append(('Lowest number of tags:', metrics.min_size))
    output(content, fp)


def output_weekly(this_week: Metrics, last_week: Metrics, fp: TextIO) -> None:
    """Emit the weekly report content."""

    output_folders_weekly(this_week, fp)
    print(file=fp)
    output_bookmarks_weekly(this_week, last_week, fp)
    print(file=fp)
    output_tags_weekly(this_week, fp)


def weekly_report(args: argparse.Namespace, file: TextIO = sys.stdout):
    """Produce the weekly report."""

    if len(args.files) == 1:
        this_week_file = args.files[0]
        base_dt = datetime_from_filename(this_week_file)
        last_week_dt = base_dt - timedelta(weeks=1)
        last_week_str = last_week_dt.strftime('%Y%m%d')
        last_week_file = re.sub(r'\d{8}', last_week_str, this_week_file)
    else:
        last_week_file, this_week_file = args.files[:2]

    this_week = get_metrics(this_week_file)
    last_week = get_metrics(last_week_file)
    finish_metrics(this_week, last_week)

    output_weekly(this_week, last_week, file)


def main():
    """Main execution loop."""

    args = parse_command_line()

    weekly_report(args)

    sys.exit(0)


if __name__ == '__main__':
    main()
